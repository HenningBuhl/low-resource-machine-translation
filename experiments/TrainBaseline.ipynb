{"cells":[{"cell_type":"markdown","id":"e96793b1","metadata":{"id":"e96793b1"},"source":["# Train Baseline"]},{"cell_type":"markdown","id":"z-qAgNSW-kR3","metadata":{"id":"z-qAgNSW-kR3"},"source":["smol explanation..."]},{"cell_type":"markdown","id":"DSA8xcUC67as","metadata":{"id":"DSA8xcUC67as"},"source":["## Setup"]},{"cell_type":"markdown","id":"27fafae3","metadata":{"id":"27fafae3"},"source":["### Environment"]},{"cell_type":"code","execution_count":3,"id":"ac63e205","metadata":{"id":"ac63e205","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1664535301111,"user_tz":-120,"elapsed":125666,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}},"outputId":"43bc73cf-bf9d-4535-a595-dc9fab047444"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive\n","\u001b[34mINFO    \u001b[0m scvi-colab: Installing scvi-tools.                                                  \n","\u001b[34mINFO    \u001b[0m scvi-colab: Install successful. Testing import.                                     \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n","  warn(f\"Failed to load image Python extension: {e}\")\n","INFO:pytorch_lightning.utilities.seed:Global seed set to 0\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/warnings.py:54: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n","  \"pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n","  return new_rank_zero_deprecation(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/low-resource-machine-translation\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.11.0\n","  Using cached torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.2.2)\n","Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.7.7)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.1.97)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2.2.1)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.64.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.5.1)\n","Collecting argparse\n","  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->-r requirements.txt (line 1)) (4.1.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning->-r requirements.txt (line 4)) (2.10.1)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning->-r requirements.txt (line 4)) (0.9.3)\n","Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning->-r requirements.txt (line 4)) (0.3.2)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning->-r requirements.txt (line 4)) (6.0)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning->-r requirements.txt (line 4)) (2022.8.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning->-r requirements.txt (line 4)) (21.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (3.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (2.23.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (22.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (1.8.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (2.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (0.13.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (0.37.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (0.4.6)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (3.17.3)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (1.48.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (3.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 4)) (1.25.11)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 4)) (3.2.0)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r requirements.txt (line 6)) (0.8.10)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r requirements.txt (line 6)) (4.9.1)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r requirements.txt (line 6)) (2.5.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r requirements.txt (line 6)) (2022.6.2)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r requirements.txt (line 6)) (0.4.5)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 7)) (7.7.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 7)) (6.1.0)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 7)) (5.3.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 7)) (5.6.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 7)) (5.3.4)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 7)) (5.3.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (0.18.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (0.70.13)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (1.3.5)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (0.3.5.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (6.0.1)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (0.10.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (3.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 9)) (3.8.0)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (5.1.1)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (5.1.1)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (7.9.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (6.1.12)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (4.4.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.2.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (2.0.10)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (4.8.0)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.18.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.2.5)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 7)) (3.0.3)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 7)) (0.2.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 7)) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 7)) (2.11.3)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 7)) (5.4.0)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 7)) (4.11.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 7)) (1.8.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 7)) (0.13.3)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->-r requirements.txt (line 7)) (23.2.1)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->-r requirements.txt (line 7)) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->-r requirements.txt (line 7)) (2.0.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (1.5.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.4)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (5.0.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.6.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.7.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->-r requirements.txt (line 7)) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->-r requirements.txt (line 7)) (2.16.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->-r requirements.txt (line 7)) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->-r requirements.txt (line 7)) (5.9.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 7)) (0.5.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r requirements.txt (line 9)) (2022.2.1)\n","Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 7)) (2.2.0)\n","Installing collected packages: torch, argparse\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1\n","    Uninstalling torch-1.12.1:\n","      Successfully uninstalled torch-1.12.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\n","Successfully installed argparse-1.4.0 torch-1.11.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse","torch"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/low-resource-machine-translation/experiments\n"]}],"source":["# If this is a notebook which is executed in colab [in_colab=True]:\n","#  1. Mount google drive and use the repository in there [mount_drive=True] (the repository must be in your google drive root folder).\n","#  2. Clone repository to remote machine [mount_drive=False].\n","in_colab = False\n","mount_drive = True\n","\n","try:\n","    # Check if running in colab.\n","    in_colab = 'google.colab' in str(get_ipython())\n","except:\n","    pass\n","\n","if in_colab:\n","    if mount_drive:\n","        # Mount google drive and navigate to it.\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","        %cd drive/MyDrive\n","    else:\n","        # Pull repository.\n","        !git clone https://github.com/HenningBuhl/low-resource-machine-translation\n","\n","    # Workaround for problem with undefined symbols (https://github.com/scverse/scvi-tools/issues/1464).\n","    !pip install --quiet scvi-colab\n","    from scvi_colab import install\n","    install()\n","\n","    # Navigate to the repository and install requirements.\n","    %cd low-resource-machine-translation\n","    !pip install -r requirements.txt\n","\n","    # Navigate to notebook location.\n","    %cd experiments"]},{"cell_type":"code","execution_count":9,"id":"56863ecd","metadata":{"id":"56863ecd","executionInfo":{"status":"ok","timestamp":1664535347058,"user_tz":-120,"elapsed":421,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}}},"outputs":[],"source":["# Add src module directory to system path for subsecuent imports.\n","import sys\n","sys.path.insert(0, '../src')"]},{"cell_type":"code","execution_count":10,"id":"2671bbc2","metadata":{"id":"2671bbc2","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"error","timestamp":1664535347059,"user_tz":-120,"elapsed":8,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}},"outputId":"f3df0a0e-586e-4f44-a0a1-67b88919b57e"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-56e428bfd201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If this is a notebook, execute this cell in order to reload changes made to the source files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Settings and module reloading (only in Jupyter Notebooks).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'util'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# If this is a notebook, execute this cell in order to reload changes made to the source files.\n","from util import is_notebook\n","\n","# Settings and module reloading (only in Jupyter Notebooks).\n","if is_notebook():\n","    # Module reloading.\n","    %load_ext autoreload\n","    %autoreload 2\n","\n","    # Plot settings.\n","    %matplotlib inline"]},{"cell_type":"markdown","id":"t116PPgfTap1","metadata":{"id":"t116PPgfTap1"},"source":["### Imports"]},{"cell_type":"code","execution_count":11,"id":"060a4467","metadata":{"id":"060a4467","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"error","timestamp":1664535351908,"user_tz":-120,"elapsed":442,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}},"outputId":"e5444762-c498-48f6-c48b-e84035ba0abe"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-1d761d45f8fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# From repository.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbenchmark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcalc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'arguments'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# From packages.\n","import pytorch_lightning as pl\n","\n","# From repository.\n","from arguments import *\n","from benchmark import *\n","from calc import *\n","from constants import *\n","from data import *\n","from layers import *\n","from metric_logging import *\n","from plotting import *\n","from path_management import *\n","from tokenizer import *\n","from transformer import *\n","from util import *"]},{"cell_type":"markdown","id":"NDQW2rot7d0n","metadata":{"id":"NDQW2rot7d0n"},"source":["### Arguments"]},{"cell_type":"code","execution_count":5,"id":"6d5b0649","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":678,"status":"ok","timestamp":1664535141856,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"},"user_tz":-120},"id":"6d5b0649","outputId":"7756019a-92d4-4777-f1c9-cc7894e135a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Arguments:\n","Namespace(batch_size=80, ckpt_path=None, d_ff=2048, d_model=512, data_dir=None, dev_run=False, drop_out_rate=0.1, enable_checkpointing=False, enable_early_stopping=False, fresh_run=False, gpus=1, learning_rate=0.0001, max_epochs=10, max_examples=-1, min_delta=0, mode='min', monitor='val_loss', mono_data_dir=None, num_heads=8, num_layers=6, num_test_examples=3000, num_val_examples=3000, num_workers=4, patience=3, seed=0, shuffle_before_split=False, shuffle_train_data=True, src_lang='de', tgt_lang='nl', track_score=True, weight_decay=0)\n"]}],"source":["# Define arguments with argparse.\n","import argparse\n","parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n","\n","# TODO help string: explain funciton \\n show arguments that are ignored or overwritten by it (when true or some other value)\n","\n","# Experiment.\n","parser.add_argument('--dev-run', default=False, type=bool, help='')\n","parser.add_argument('--fresh-run', default=False, type=bool, help='Ignores all cashed data on disk, reruns generation and overwrites data')\n","parser.add_argument('--seed', default=0, type=int, help='')\n","parser.add_argument('--src-lang', default='de', type=str, help='if help string is empty, default value will not be shown...')\n","parser.add_argument('--tgt-lang', default='nl', type=str, help='')\n","#parser.add_argument('--eval-before-train', action='store_true', help='Evaluation (train + val) before training')\n","\n","# Metrics.\n","parser.add_argument('--track-score', default=True, type=bool, help='SacreBLEU score')\n","#parser.add_argument('--track-ter', default=False, type=bool, help='translation error rate')\n","#parser.add_argument('--track-tp', default=False, type=bool, help='translation perplexity')\n","\n","# Data.\n","#parser.add_argument('--dataset', default='WikiMatrix', type=str, help='Only one dataset. ALL setups that want to use more than one file as input should use data-dir because the cached data cannot be atributed to the correct experiments settings otherwise (or that would be bothersome)')\n","# TODO build data-dir from CONST_DATA_DIR and src-tgt key combination (look in which order it is present) if argument is none.\n","parser.add_argument('--data-dir', default=None, type=str, help='1. empty dir, populated with data from datasets arg 2. en.txt + de.txt 3. en/**.txt + de/**.txt 4. en/train.txt, en/val.txt, en/test.txt + de/train.txt, de/val.txt, de/test.txt')\n","parser.add_argument('--shuffle-before-split', default=False, type=bool, help='')\n","parser.add_argument('--num-val-examples', default=3000, type=int, help='val, test...') \n","parser.add_argument('--num-test-examples', default=3000, type=int, help='val, test...')\n","#parser.add_argument('--cache-combined-data', default=False, type=bool, help='save combined (single .txt file) data to disk')\n","#parser.add_argument('--cache-split-data', default=False, type=bool, help='save split data (train, val, test) data to disk')\n","#parser.add_argument('--cache-tokenized-data', default=True, type=bool, help='save tokenized data to disk')\n","#parser.add_argument('--cache-shifted-data', default=False, type=bool, help='save preprocessed to disk')\n","#parser.add_argument('--cache-padded-data', default=False, type=bool, help='save preprocessed to disk')\n","#parser.add_argument('--use-collate-fn', default=False, type=bool, help='(basically, everything that is not already cached is done in collate_fn instead of fully loading the data) If the fully collated (preprocessed) data is not cached and loaded, use collate_fn (for either padding+shifting OR tokenization+padding+shifting depending on cache settings)')\n","#parser.add_argument('--lazy-load-data', default=False, type=bool, type=str, help='!use custom dataset with chunksize (or similar method [add another param for max size MB/GB memory available?]) in getitem (also for saving? data would not fit all in memory to save tokenized or padded+shifted data at once)! if the data is so big, that not even the raw text can be used in memory completely, this will dynamically load batches from disk if set to false')\n","\n","# Tokenization.\n","parser.add_argument('--mono-data-dir', default=None, type=str, help='dir containing files of monlingual data for tokenization')\n","# Add more tokenizers (+different set of arguments for src, pvt and tgt tokenier each...)?\n","#parser.add_argument('--tokenizer-dir', default=None, type=str, help='Use tokenizer in path or save to the location if not exist.')\n","#parser.add_argument('--pad-id', default=0, type=int, help='')\n","#parser.add_argument('--sos-id', default=1, type=int, help='')\n","#parser.add_argument('--eos-id', default=2, type=int, help='')\n","#parser.add_argument('--unk-id', default=3, type=int, help='')\n","#parser.add_argument('--vocab-size', default=16000, type=int, help='')\n","#parser.add_argument('--character-coverage', default=1.0, type=float, help='')\n","#parser.add_argument('--model-type', default='unigram', type=str, choices=['unigram', 'bpe', 'char'], help='')\n","\n","# Architecture.\n","parser.add_argument('--num-layers', default=6, type=int, help='')\n","parser.add_argument('--d-model', default=512, type=int, help='')\n","parser.add_argument('--drop-out-rate', default=0.1, type=float, help='')\n","parser.add_argument('--num-heads', default=8, type=int, help='')\n","parser.add_argument('--d-ff', default=2048, type=int, help='')\n","#parser.add_argument('--max-len', default=128, type=int, help='')\n","\n","# Optimizer.\n","# chose optimizer?\n","parser.add_argument('--learning-rate', default=1e-4, type=float, help='')\n","parser.add_argument('--weight-decay', default=0, type=float, help='')\n","#parser.add_argument('--beta-1', default=0.9, type=float, help='')\n","#parser.add_argument('--beta-2', default=0.999, type=float, help='')\n","#parser.add_argument('--scheduling', default=0, type=float, help='')\n","\n","# Training.\n","parser.add_argument('--batch-size', default=80, type=int, help='')\n","#parser.add_argument('--soft-labels', default=0, type=float, help='distance from 0 and 1...')\n","parser.add_argument('--max-epochs', default=10, type=int, help='')\n","parser.add_argument('--max-examples', default=-1, type=int, help='')\n","parser.add_argument('--shuffle-train-data', default=True, type=bool, help='')\n","parser.add_argument('--gpus', default=1, type=int, help='')\n","parser.add_argument('--num-workers', default=4, type=int, help='')\n","parser.add_argument('--ckpt-path', default=None, type=str, help='')\n","#parser.add_argument('--resume-last-ckpt', default=False, type=bool, help='uses last.ckpt file...')\n","\n","# Early Stopping + Model Checkpoint.\n","parser.add_argument('--enable-early-stopping', default=False, type=bool, help='')\n","parser.add_argument('--enable-checkpointing', default=False, type=bool, help='')\n","parser.add_argument('--monitor', default='val_loss', type=str, help='')\n","parser.add_argument('--min-delta', default=0, type=float, help='')\n","parser.add_argument('--patience', default=3, type=int, help='')\n","parser.add_argument('--mode', default='min', type=str, help='')\n","# TODO save last model, best model, last checkpoint.\n","\n","# Result Exporting.\n","#parser.add_argument('--export-batch-data', default=False, type=bool, help='export batch data (not only epoch data)')\n","#parser.add_argument('--export-svgs', default=True, type=bool, help='exports an svg with plt for each actively tracked metric')\n","#parser.add_argument('--export-metric-files', default=True, type=bool, help='Additionally saves each metric (per key in metrics dict) to a separate file. Values are separated by a new line.')\n","\n","# Parse args.\n","if is_notebook(): sys.argv = ['-f']  # Used to make argparse work in jupyter notebooks (all args must be optional).\n","args, _ = parser.parse_known_args()\n","print('Arguments:')\n","print(args)"]},{"cell_type":"code","execution_count":6,"id":"2VWCabcjvgiT","metadata":{"id":"2VWCabcjvgiT","executionInfo":{"status":"ok","timestamp":1664535141857,"user_tz":-120,"elapsed":21,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}}},"outputs":[],"source":["# Auto-infer args.\n","auto_infer_args(args)"]},{"cell_type":"code","execution_count":7,"id":"5pEUXxmyTMmw","metadata":{"id":"5pEUXxmyTMmw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664535141858,"user_tz":-120,"elapsed":21,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}},"outputId":"81f32ff3-b9f4-48ea-c727-3f02f1b2028a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Adjusted args in notebook\n"]}],"source":["# Adjust arguments for test purposes.\n","if is_notebook() and True:  # Quickly turn on and off with 'and True/False'.\n","    #args.dev_run = True\n","    #args.fresh_run = True\n","    args.batch_size = 10\n","    args.max_examples = 20\n","    args.num_val_examples = 10\n","    args.num_test_examples = 10\n","    print('Adjusted args in notebook')"]},{"cell_type":"code","execution_count":8,"id":"Jeeda_XMY5lZ","metadata":{"id":"Jeeda_XMY5lZ","executionInfo":{"status":"ok","timestamp":1664535141859,"user_tz":-120,"elapsed":18,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}}},"outputs":[],"source":["# Sanity check args.\n","sanity_check_args(args)"]},{"cell_type":"markdown","id":"OpSSObjs69g6","metadata":{"id":"OpSSObjs69g6"},"source":["### Seed"]},{"cell_type":"code","execution_count":9,"id":"oeC5Td1c69A7","metadata":{"id":"oeC5Td1c69A7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664535141859,"user_tz":-120,"elapsed":17,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}},"outputId":"ccddbf5f-3819-437e-dfa1-7f1046ccb1d9"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.seed:Global seed set to 0\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":9}],"source":["# Set seed.\n","from pytorch_lightning import seed_everything\n","seed_everything(args.seed, workers=True)"]},{"cell_type":"markdown","id":"jcklieExTMm2","metadata":{"id":"jcklieExTMm2"},"source":["### Paths"]},{"cell_type":"code","execution_count":10,"id":"428bec54","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664535141859,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"},"user_tz":-120},"id":"428bec54","outputId":"deaaf7c2-af78-4ae7-a661-fe3e38424ccc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dir \"./data\" already exists.\n","Dir \"./models\" already exists.\n","Dir \"./runs\" already exists.\n","Dir \"./tokenizers\" already exists.\n","Dir \"./runs/baseline-de-nl-2022.09.30-10.52.21\" does not exist, creating it.\n","Dir \"./runs/baseline-de-nl-2022.09.30-10.52.21/baseline\" does not exist, creating it.\n","Dir \"./runs/baseline-de-nl-2022.09.30-10.52.21/baseline/checkpoints\" does not exist, creating it.\n","Dir \"./runs/baseline-de-nl-2022.09.30-10.52.21/baseline/metrics\" does not exist, creating it.\n"]}],"source":["# Create directories and create file names.\n","pm = ExperimentPathManager(f'baseline-{args.src_lang}-{args.tgt_lang}', 'baseline')\n","pm.init()"]},{"cell_type":"code","source":["# Save arguments.\n","save_dict(pm.args_file, args.__dict__)"],"metadata":{"id":"WHCPZbsxJKFP","executionInfo":{"status":"ok","timestamp":1664535141860,"user_tz":-120,"elapsed":11,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}}},"id":"WHCPZbsxJKFP","execution_count":11,"outputs":[]},{"cell_type":"markdown","id":"rkW_NDcO6Juj","metadata":{"id":"rkW_NDcO6Juj"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"zKYC6ckyhpIm","metadata":{"id":"zKYC6ckyhpIm","executionInfo":{"status":"ok","timestamp":1664535141861,"user_tz":-120,"elapsed":10,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}}},"outputs":[],"source":["pp = PreProcessor(args.src_lang, args.tgt_lang, args.data_dir)"]},{"cell_type":"markdown","id":"ox3-TzsEXxdX","metadata":{"id":"ox3-TzsEXxdX"},"source":["### Data Split"]},{"cell_type":"code","execution_count":13,"id":"7ggKhSn0GV5f","metadata":{"id":"7ggKhSn0GV5f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664535142361,"user_tz":-120,"elapsed":509,"user":{"displayName":"Valkyrias Sairyklav","userId":"01454228790974734447"}},"outputId":"feb94b54-39b4-4c0f-ce18-b6983746bb79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data is already split.\n"]}],"source":["# Split data into (train, val, test) sets.\n","pp.split_data(args.shuffle_before_split, args.num_val_examples, args.num_test_examples, args.fresh_run)"]},{"cell_type":"markdown","id":"l2iA4BU06AS1","metadata":{"id":"l2iA4BU06AS1"},"source":["### Tokenizers"]},{"cell_type":"code","execution_count":null,"id":"ujigJp-A6AL-","metadata":{"id":"ujigJp-A6AL-"},"outputs":[],"source":["# Load tokenizers.\n","src_tokenizer = TokenizerBuilder(args.src_lang, args.data_dir, args.mono_data_dir).build()\n","tgt_tokenizer = TokenizerBuilder(args.tgt_lang, args.data_dir, args.mono_data_dir).build()"]},{"cell_type":"markdown","id":"bSN0TBQf6AGG","metadata":{"id":"bSN0TBQf6AGG"},"source":["### Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"NNeDWIrXWhBH","metadata":{"id":"NNeDWIrXWhBH"},"outputs":[],"source":["# Load dataloaders.\n","train_dataloader, val_dataloader, test_dataloader = pp.pre_process(src_tokenizer, tgt_tokenizer, args.batch_size, args.shuffle_train_data, args.max_examples)"]},{"cell_type":"markdown","id":"7yKXjhQF7QEG","metadata":{"id":"7yKXjhQF7QEG"},"source":["## Experiment"]},{"cell_type":"markdown","id":"yYT-y8Ng6sd7","metadata":{"id":"yYT-y8Ng6sd7"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"id":"24da631a","metadata":{"id":"24da631a"},"outputs":[],"source":["# Create model.\n","model = Transformer(src_tokenizer,\n","                    tgt_tokenizer,\n","                    args.learning_rate,\n","                    args.weight_decay,\n","                    args.num_layers,\n","                    args.d_model,\n","                    args.drop_out_rate,\n","                    args.num_heads,\n","                    args.d_ff,\n","                    )\n","\n","print('Created model.')"]},{"cell_type":"code","execution_count":null,"id":"C10ZdzrB_P0s","metadata":{"id":"C10ZdzrB_P0s"},"outputs":[],"source":["# Save untrained model.\n","model.save(pm.baseline.untrained_model_file)"]},{"cell_type":"markdown","id":"ltyUst9C6uag","metadata":{"id":"ltyUst9C6uag"},"source":["### Training"]},{"cell_type":"code","source":["# Create callbacks.\n","callbacks = []\n","\n","if args.enable_checkpointing:\n","    model_checkpoint = pl.callbacks.ModelCheckpoint(\n","        monitor=args.monitor,\n","        dirpath=pm.baseline.checkpoint_dir,\n","        filename='{epoch}-{val_loss:.2f}',\n","        save_top_k=1,\n","        save_last=True,\n","        every_n_epochs=1,\n","        verbose=True,\n","    )\n","    callbacks.append(model_checkpoint)\n","\n","if args.enable_early_stopping:\n","    early_stopping_callback = pl.callbacks.EarlyStopping(\n","        monitor=args.monitor,\n","        min_delta=args.min_delta,\n","        patience=args.patience,\n","        mode=args.mode,\n","        verbose=True,\n","    )\n","    callbacks.append(early_stopping_callback)"],"metadata":{"id":"HV-98vnbuklw"},"id":"HV-98vnbuklw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create metric logger.\n","metric_logger = MetricLogger(args.track_score)"],"metadata":{"id":"edyzoE-JukoR"},"id":"edyzoE-JukoR","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"6eceaec8","metadata":{"id":"6eceaec8"},"outputs":[],"source":["# Create trainer.\n","trainer = pl.Trainer(deterministic=True,\n","                  fast_dev_run=args.dev_run,\n","                  max_epochs=args.max_epochs,\n","                  logger=metric_logger,\n","                  log_every_n_steps=1,\n","                  enable_checkpointing=args.enable_checkpointing,\n","                  default_root_dir=pm.baseline.checkpoint_dir,\n","                  callbacks=callbacks,\n","                  gpus=args.gpus if str(device) == 'cuda' else 0)\n","\n","print('Created trainer.')"]},{"cell_type":"code","execution_count":null,"id":"9b270ae5","metadata":{"id":"9b270ae5","scrolled":false},"outputs":[],"source":["# Training.\n","trainer.fit(model,\n","            train_dataloaders=train_dataloader,\n","            val_dataloaders=val_dataloader,\n","            ckpt_path=args.ckpt_path)"]},{"cell_type":"code","execution_count":null,"id":"523307ae","metadata":{"id":"523307ae"},"outputs":[],"source":["# Save model.\n","model.save(pm.baseline.model_file)"]},{"cell_type":"markdown","id":"c_TH_oUw5J07","metadata":{"id":"c_TH_oUw5J07"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"id":"30b198e8","metadata":{"id":"30b198e8"},"outputs":[],"source":["# Testing.\n","test_metrics = trainer.test(model, dataloaders=test_dataloader)"]},{"cell_type":"markdown","id":"DIwsznuh5LYp","metadata":{"id":"DIwsznuh5LYp"},"source":["## Exporting Results"]},{"cell_type":"code","source":["# Save recorded metrics.\n","metric_logger.manual_save(pm.baseline.metrics_dir, pm.baseline.metrics_file)"],"metadata":{"id":"Db8S-unQ2wF_"},"id":"Db8S-unQ2wF_","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"3adf0a0c","metadata":{"id":"3adf0a0c"},"outputs":[],"source":["# Save metric plots.\n","metrics = ['loss']\n","if args.track_score: metrics.append('score')\n","\n","for metric in metrics:\n","    plot_metric(metric_logger.metrics, metric, save_path=pm.baseline.metrics_svg_template.format(metric))"]},{"cell_type":"code","execution_count":null,"id":"8c439860","metadata":{"id":"8c439860"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"37cef9f8","metadata":{"id":"37cef9f8"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"e16c6ae93e97f8b72f7c60789e33aa05f059bdee2efc0781f4556fc1fbea3a2d"}}},"nbformat":4,"nbformat_minor":5}