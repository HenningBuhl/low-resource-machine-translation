{"cells":[{"cell_type":"markdown","id":"e96793b1","metadata":{"id":"e96793b1"},"source":["# Train Baseline"]},{"cell_type":"markdown","id":"z-qAgNSW-kR3","metadata":{"id":"z-qAgNSW-kR3"},"source":["smol explanation..."]},{"cell_type":"markdown","id":"DSA8xcUC67as","metadata":{"id":"DSA8xcUC67as"},"source":["## Setup"]},{"cell_type":"markdown","id":"27fafae3","metadata":{"id":"27fafae3"},"source":["### Environment"]},{"cell_type":"code","execution_count":null,"id":"ac63e205","metadata":{"id":"ac63e205"},"outputs":[],"source":["# If this is a notebook which is executed in colab [in_colab=True]:\n","#  1. Mount google drive and use the repository in there [mount_drive=True] (the repository must be in your google drive root folder).\n","#  2. Clone repository to remote machine [mount_drive=False].\n","in_colab = False\n","mount_drive = True\n","\n","try:\n","    # Check if running in colab.\n","    in_colab = 'google.colab' in str(get_ipython())\n","except:\n","    pass\n","\n","if in_colab:\n","    if mount_drive:\n","        # Mount google drive and navigate to it.\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","        %cd drive/MyDrive\n","    else:\n","        # Pull repository.\n","        !git clone https://github.com/HenningBuhl/low-resource-machine-translation\n","\n","    # Workaround for problem with undefined symbols (https://github.com/scverse/scvi-tools/issues/1464).\n","    !pip install --quiet scvi-colab\n","    from scvi_colab import install\n","    install()\n","\n","    # Navigate to the repository and install requirements.\n","    %cd low-resource-machine-translation\n","    !pip install -r requirements.txt\n","\n","    # Navigate to notebook location.\n","    %cd experiments"]},{"cell_type":"code","execution_count":null,"id":"56863ecd","metadata":{"id":"56863ecd"},"outputs":[],"source":["# Add src module directory to system path for subsecuent imports.\n","import sys\n","sys.path.insert(0, '../src')"]},{"cell_type":"code","execution_count":null,"id":"2671bbc2","metadata":{"id":"2671bbc2"},"outputs":[],"source":["# If this is a notebook, execute this cell in order to reload changes made to the source files.\n","from util import is_notebook\n","\n","# Settings and module reloading (only in Jupyter Notebooks).\n","if is_notebook():\n","    # Module reloading.\n","    %load_ext autoreload\n","    %autoreload 2\n","\n","    # Plot settings.\n","    %matplotlib inline"]},{"cell_type":"markdown","id":"t116PPgfTap1","metadata":{"id":"t116PPgfTap1"},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"id":"060a4467","metadata":{"id":"060a4467"},"outputs":[],"source":["# From packages.\n","import pytorch_lightning as pl\n","\n","# From repository.\n","from arguments import *\n","from benchmark import *\n","from calc import *\n","from constants import *\n","from data import *\n","from layers import *\n","from metric_logging import *\n","from plotting import *\n","from path_management import *\n","from tokenizer import *\n","from transformer import *\n","from util import *"]},{"cell_type":"markdown","id":"NDQW2rot7d0n","metadata":{"id":"NDQW2rot7d0n"},"source":["### Arguments"]},{"cell_type":"code","execution_count":null,"id":"6d5b0649","metadata":{"id":"6d5b0649"},"outputs":[],"source":["# Define arguments with argparse.\n","import argparse\n","parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n","\n","# TODO help string: explain funciton \\n show arguments that are ignored or overwritten by it (when true or some other value)\n","\n","# Experiment.\n","parser.add_argument('--dev-run', default=False, type=bool, help='')\n","parser.add_argument('--fresh-run', default=False, type=bool, help='Ignores all cashed data on disk, reruns generation and overwrites data')\n","parser.add_argument('--seed', default=0, type=int, help='')\n","parser.add_argument('--src-lang', default='de', type=str, help='if help string is empty, default value will not be shown...')\n","parser.add_argument('--tgt-lang', default='nl', type=str, help='')\n","#parser.add_argument('--eval-before-train', action='store_true', help='Evaluation (train + val) before training')\n","\n","# Metrics.\n","parser.add_argument('--track-score', default=True, type=bool, help='SacreBLEU score')\n","#parser.add_argument('--track-ter', default=False, type=bool, help='translation error rate')\n","#parser.add_argument('--track-tp', default=False, type=bool, help='translation perplexity')\n","\n","# Data.\n","#parser.add_argument('--dataset', default='WikiMatrix', type=str, help='Only one dataset. ALL setups that want to use more than one file as input should use data-dir because the cached data cannot be atributed to the correct experiments settings otherwise (or that would be bothersome)')\n","# TODO build data-dir from CONST_DATA_DIR and src-tgt key combination (look in which order it is present) if argument is none.\n","parser.add_argument('--data-dir', default=None, type=str, help='1. empty dir, populated with data from datasets arg 2. en.txt + de.txt 3. en/**.txt + de/**.txt 4. en/train.txt, en/val.txt, en/test.txt + de/train.txt, de/val.txt, de/test.txt')\n","parser.add_argument('--shuffle-before-split', default=False, type=bool, help='')\n","parser.add_argument('--num-val-examples', default=3000, type=int, help='val, test...') \n","parser.add_argument('--num-test-examples', default=3000, type=int, help='val, test...')\n","#parser.add_argument('--cache-combined-data', default=False, type=bool, help='save combined (single .txt file) data to disk')\n","#parser.add_argument('--cache-split-data', default=False, type=bool, help='save split data (train, val, test) data to disk')\n","#parser.add_argument('--cache-tokenized-data', default=True, type=bool, help='save tokenized data to disk')\n","#parser.add_argument('--cache-shifted-data', default=False, type=bool, help='save preprocessed to disk')\n","#parser.add_argument('--cache-padded-data', default=False, type=bool, help='save preprocessed to disk')\n","#parser.add_argument('--use-collate-fn', default=False, type=bool, help='(basically, everything that is not already cached is done in collate_fn instead of fully loading the data) If the fully collated (preprocessed) data is not cached and loaded, use collate_fn (for either padding+shifting OR tokenization+padding+shifting depending on cache settings)')\n","#parser.add_argument('--lazy-load-data', default=False, type=bool, type=str, help='!use custom dataset with chunksize (or similar method [add another param for max size MB/GB memory available?]) in getitem (also for saving? data would not fit all in memory to save tokenized or padded+shifted data at once)! if the data is so big, that not even the raw text can be used in memory completely, this will dynamically load batches from disk if set to false')\n","\n","# Tokenization.\n","parser.add_argument('--mono-data-dir', default=None, type=str, help='dir containing files of monlingual data for tokenization')\n","# Add more tokenizers (+different set of arguments for src, pvt and tgt tokenier each...)?\n","#parser.add_argument('--tokenizer-dir', default=None, type=str, help='Use tokenizer in path or save to the location if not exist.')\n","#parser.add_argument('--pad-id', default=0, type=int, help='')\n","#parser.add_argument('--sos-id', default=1, type=int, help='')\n","#parser.add_argument('--eos-id', default=2, type=int, help='')\n","#parser.add_argument('--unk-id', default=3, type=int, help='')\n","#parser.add_argument('--vocab-size', default=16000, type=int, help='')\n","#parser.add_argument('--character-coverage', default=1.0, type=float, help='')\n","#parser.add_argument('--model-type', default='unigram', type=str, choices=['unigram', 'bpe', 'char'], help='')\n","\n","# Architecture.\n","parser.add_argument('--num-layers', default=6, type=int, help='')\n","parser.add_argument('--d-model', default=512, type=int, help='')\n","parser.add_argument('--drop-out-rate', default=0.1, type=float, help='')\n","parser.add_argument('--num-heads', default=8, type=int, help='')\n","parser.add_argument('--d-ff', default=2048, type=int, help='')\n","#parser.add_argument('--max-len', default=128, type=int, help='')\n","\n","# Optimizer.\n","# chose optimizer?\n","parser.add_argument('--learning-rate', default=1e-4, type=float, help='')\n","parser.add_argument('--weight-decay', default=0, type=float, help='')\n","#parser.add_argument('--beta-1', default=0.9, type=float, help='')\n","#parser.add_argument('--beta-2', default=0.999, type=float, help='')\n","#parser.add_argument('--scheduling', default=0, type=float, help='')\n","\n","# Training.\n","parser.add_argument('--batch-size', default=80, type=int, help='')\n","#parser.add_argument('--soft-labels', default=0, type=float, help='distance from 0 and 1...')\n","parser.add_argument('--max-epochs', default=10, type=int, help='')\n","parser.add_argument('--max-examples', default=-1, type=int, help='')\n","parser.add_argument('--shuffle-train-data', default=True, type=bool, help='')\n","parser.add_argument('--gpus', default=1, type=int, help='')\n","parser.add_argument('--num-workers', default=4, type=int, help='')\n","parser.add_argument('--ckpt-path', default=None, type=str, help='')\n","\n","# Early Stopping + Model Checkpoint.\n","parser.add_argument('--enable-early-stopping', default=False, type=bool, help='')\n","parser.add_argument('--enable-checkpointing', default=False, type=bool, help='')\n","parser.add_argument('--monitor', default='val_loss', type=str, help='')\n","parser.add_argument('--min-delta', default=0, type=float, help='')\n","parser.add_argument('--patience', default=3, type=int, help='')\n","parser.add_argument('--mode', default='min', type=str, help='')\n","# TODO save last model, best model, last checkpoint.\n","\n","# Exporting.\n","#parser.add_argument('--export-batch-data', default=False, type=bool, help='export batch data (not only epoch data)')\n","#parser.add_argument('--export-svgs', default=True, type=bool, help='exports an svg with plt for each actively tracked metric')\n","#parser.add_argument('--export-metric-files', default=True, type=bool, help='Additionally saves each metric (per key in metrics dict) to a separate file. Values are separated by a new line.')\n","\n","# Parse args.\n","if is_notebook():\n","    sys.argv = ['-f']  # Used to make argparse work in jupyter notebooks (all args must be optional).\n","    args, _ = parser.parse_known_args()  # -f can lead to unknown argument.\n","else:\n","    args = parser.parse_args()\n","\n","# Print args.\n","print('Arguments:')\n","print(args)"]},{"cell_type":"code","execution_count":null,"id":"2VWCabcjvgiT","metadata":{"id":"2VWCabcjvgiT"},"outputs":[],"source":["# Auto-infer args.\n","auto_infer_args(args)"]},{"cell_type":"code","execution_count":null,"id":"5pEUXxmyTMmw","metadata":{"id":"5pEUXxmyTMmw"},"outputs":[],"source":["# Adjust arguments for test purposes.\n","if is_notebook() and True:  # Quickly turn on and off with 'and True/False'.\n","    #args.dev_run = True\n","    #args.fresh_run = True\n","    args.max_epochs = 2\n","    args.batch_size = 1\n","    args.max_examples = 2\n","    args.num_val_examples = 1\n","    args.num_test_examples = 1\n","\n","    args.track_score = True\n","    print('Adjusted args in notebook')"]},{"cell_type":"code","execution_count":null,"id":"Jeeda_XMY5lZ","metadata":{"id":"Jeeda_XMY5lZ"},"outputs":[],"source":["# Sanity check args.\n","sanity_check_args(args)"]},{"cell_type":"markdown","id":"OpSSObjs69g6","metadata":{"id":"OpSSObjs69g6"},"source":["### Seed"]},{"cell_type":"code","execution_count":null,"id":"oeC5Td1c69A7","metadata":{"id":"oeC5Td1c69A7"},"outputs":[],"source":["# Set seed.\n","from pytorch_lightning import seed_everything\n","seed_everything(args.seed, workers=True)"]},{"cell_type":"markdown","id":"jcklieExTMm2","metadata":{"id":"jcklieExTMm2"},"source":["### Paths"]},{"cell_type":"code","execution_count":null,"id":"428bec54","metadata":{"id":"428bec54"},"outputs":[],"source":["# Create directories and create file names.\n","pm = ExperimentPathManager(f'baseline-{args.src_lang}-{args.tgt_lang}', 'baseline')\n","pm.init()"]},{"cell_type":"code","source":["# Save arguments.\n","save_dict(pm.args_file, args.__dict__)"],"metadata":{"id":"WHCPZbsxJKFP"},"id":"WHCPZbsxJKFP","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"rkW_NDcO6Juj","metadata":{"id":"rkW_NDcO6Juj"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"zKYC6ckyhpIm","metadata":{"id":"zKYC6ckyhpIm"},"outputs":[],"source":["# Create PreProcessor.\n","pp = PreProcessor(args.src_lang, args.tgt_lang, args.data_dir)"]},{"cell_type":"markdown","id":"ox3-TzsEXxdX","metadata":{"id":"ox3-TzsEXxdX"},"source":["### Splitting"]},{"cell_type":"code","execution_count":null,"id":"7ggKhSn0GV5f","metadata":{"id":"7ggKhSn0GV5f"},"outputs":[],"source":["# Split data into (train, val, test) sets.\n","pp.split_data(args.shuffle_before_split, args.num_val_examples, args.num_test_examples, args.fresh_run)"]},{"cell_type":"markdown","id":"l2iA4BU06AS1","metadata":{"id":"l2iA4BU06AS1"},"source":["### Tokenizers"]},{"cell_type":"code","execution_count":null,"id":"ujigJp-A6AL-","metadata":{"id":"ujigJp-A6AL-"},"outputs":[],"source":["# Load tokenizers.\n","src_tokenizer = TokenizerBuilder(args.src_lang, args.data_dir, args.mono_data_dir).build()\n","tgt_tokenizer = TokenizerBuilder(args.tgt_lang, args.data_dir, args.mono_data_dir).build()"]},{"cell_type":"markdown","id":"bSN0TBQf6AGG","metadata":{"id":"bSN0TBQf6AGG"},"source":["### Preparation"]},{"cell_type":"code","execution_count":null,"id":"NNeDWIrXWhBH","metadata":{"id":"NNeDWIrXWhBH"},"outputs":[],"source":["# Load dataloaders.\n","train_dataloader, val_dataloader, test_dataloader = pp.pre_process(src_tokenizer, tgt_tokenizer, args.batch_size, args.shuffle_train_data, args.max_examples)"]},{"cell_type":"markdown","id":"7yKXjhQF7QEG","metadata":{"id":"7yKXjhQF7QEG"},"source":["## Experiment"]},{"cell_type":"markdown","id":"yYT-y8Ng6sd7","metadata":{"id":"yYT-y8Ng6sd7"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"id":"24da631a","metadata":{"id":"24da631a"},"outputs":[],"source":["# Create model.\n","model = Transformer(src_tokenizer,\n","                    tgt_tokenizer,\n","                    args.learning_rate,\n","                    args.weight_decay,\n","                    args.num_layers,\n","                    args.d_model,\n","                    args.drop_out_rate,\n","                    args.num_heads,\n","                    args.d_ff,\n","                    args.track_score\n","                    )"]},{"cell_type":"code","execution_count":null,"id":"C10ZdzrB_P0s","metadata":{"id":"C10ZdzrB_P0s"},"outputs":[],"source":["# Save untrained model.\n","model.save(pm.baseline.untrained_model_file)"]},{"cell_type":"markdown","id":"ltyUst9C6uag","metadata":{"id":"ltyUst9C6uag"},"source":["### Training"]},{"cell_type":"code","source":["# Create callbacks.\n","callbacks = []\n","\n","if args.enable_checkpointing:\n","    model_checkpoint = pl.callbacks.ModelCheckpoint(\n","        monitor=args.monitor,\n","        dirpath=pm.baseline.checkpoint_dir,\n","        filename='{epoch}-{val_loss:.2f}',\n","        save_top_k=1,\n","        save_last=True,\n","        every_n_epochs=1,\n","        verbose=True,\n","    )\n","    callbacks.append(model_checkpoint)\n","\n","if args.enable_early_stopping:\n","    early_stopping_callback = pl.callbacks.EarlyStopping(\n","        monitor=args.monitor,\n","        min_delta=args.min_delta,\n","        patience=args.patience,\n","        mode=args.mode,\n","        verbose=True,\n","    )\n","    callbacks.append(early_stopping_callback)"],"metadata":{"id":"HV-98vnbuklw"},"id":"HV-98vnbuklw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create metric logger.\n","metric_logger = MetricLogger(args.track_score)"],"metadata":{"id":"edyzoE-JukoR"},"id":"edyzoE-JukoR","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"6eceaec8","metadata":{"id":"6eceaec8"},"outputs":[],"source":["# Create trainer.\n","trainer = pl.Trainer(deterministic=True,\n","                  fast_dev_run=args.dev_run,\n","                  max_epochs=args.max_epochs,\n","                  logger=metric_logger,\n","                  log_every_n_steps=1,\n","                  enable_checkpointing=args.enable_checkpointing,\n","                  default_root_dir=pm.baseline.checkpoint_dir,\n","                  callbacks=callbacks,\n","                  gpus=args.gpus if str(device) == 'cuda' else 0)"]},{"cell_type":"code","execution_count":null,"id":"9b270ae5","metadata":{"id":"9b270ae5","scrolled":false},"outputs":[],"source":["# Training.\n","trainer.fit(model,\n","            train_dataloaders=train_dataloader,\n","            val_dataloaders=val_dataloader,\n","            ckpt_path=args.ckpt_path)"]},{"cell_type":"code","execution_count":null,"id":"523307ae","metadata":{"id":"523307ae"},"outputs":[],"source":["# Save model.\n","model.save(pm.baseline.model_file)"]},{"cell_type":"markdown","id":"c_TH_oUw5J07","metadata":{"id":"c_TH_oUw5J07"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"id":"30b198e8","metadata":{"id":"30b198e8"},"outputs":[],"source":["# Testing.\n","test_metrics = trainer.test(model, dataloaders=test_dataloader)"]},{"cell_type":"markdown","id":"DIwsznuh5LYp","metadata":{"id":"DIwsznuh5LYp"},"source":["## Exporting Results"]},{"cell_type":"code","source":["# Save recorded metrics.\n","metric_logger.manual_save(pm.baseline.metrics_dir, pm.baseline.metrics_file)"],"metadata":{"id":"Db8S-unQ2wF_"},"id":"Db8S-unQ2wF_","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"3adf0a0c","metadata":{"id":"3adf0a0c"},"outputs":[],"source":["# Save metric plots.\n","for metric in model.tracked_metrics:\n","    plot_metric(metric_logger.metrics, metric, save_path=pm.baseline.metrics_svg_template.format(metric))"]},{"cell_type":"code","execution_count":null,"id":"37cef9f8","metadata":{"id":"37cef9f8"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true,"private_outputs":true},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"e16c6ae93e97f8b72f7c60789e33aa05f059bdee2efc0781f4556fc1fbea3a2d"}}},"nbformat":4,"nbformat_minor":5}