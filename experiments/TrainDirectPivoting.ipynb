{"cells":[{"cell_type":"markdown","source":["# Train Direct Pivoting"],"metadata":{"id":"KVsD8u--YG74"},"id":"KVsD8u--YG74"},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"iXzLI0nkYG5u"},"id":"iXzLI0nkYG5u"},{"cell_type":"markdown","source":["### Environment"],"metadata":{"id":"GdK1e3SqYG1H"},"id":"GdK1e3SqYG1H"},{"cell_type":"code","execution_count":null,"id":"e219183d","metadata":{"id":"e219183d"},"outputs":[],"source":["# If this is a notebook which is executed in colab [in_colab=True]:\n","#  1. Mount google drive and use the repository in there [mount_drive=True] (the repository must be in your google drive root folder).\n","#  2. Clone repository to remote machine [mount_drive=False].\n","in_colab = False\n","mount_drive = True\n","\n","try:\n","    # Check if running in colab.\n","    in_colab = 'google.colab' in str(get_ipython())\n","except:\n","    pass\n","\n","if in_colab:\n","    if mount_drive:\n","        # Mount google drive and navigate to it.\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","        %cd drive/MyDrive\n","    else:\n","        # Pull repository.\n","        !git clone https://github.com/HenningBuhl/low-resource-machine-translation\n","\n","    # Workaround for problem with undefined symbols (https://github.com/scverse/scvi-tools/issues/1464).\n","    !pip install --quiet scvi-colab\n","    from scvi_colab import install\n","    install()\n","\n","    # Navigate to the repository and install requirements.\n","    %cd low-resource-machine-translation\n","    !pip install -r requirements.txt\n","\n","    # Navigate to notebook location.\n","    %cd experiments"]},{"cell_type":"code","execution_count":null,"id":"aa380261","metadata":{"id":"aa380261"},"outputs":[],"source":["# Add src module directory to system path for subsecuent imports.\n","import sys\n","sys.path.insert(0, '../src')"]},{"cell_type":"code","execution_count":null,"id":"843ca766","metadata":{"id":"843ca766"},"outputs":[],"source":["from util import is_notebook\n","\n","# Settings and module reloading (only in Jupyter Notebooks).\n","if is_notebook():\n","    # Module reloading.\n","    %load_ext autoreload\n","    %autoreload 2\n","\n","    # Plot settings.\n","    %matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"t116PPgfTap1"},"source":["### Imports"],"id":"t116PPgfTap1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"060a4467"},"outputs":[],"source":["# From packages.\n","import pytorch_lightning as pl\n","\n","# From repository.\n","from arguments import *\n","from benchmark import *\n","from calc import *\n","from constants import *\n","from data import *\n","from layers import *\n","from metric_logging import *\n","from plotting import *\n","from path_management import *\n","from tokenizer import *\n","from transformer import *\n","from util import *"],"id":"060a4467"},{"cell_type":"markdown","metadata":{"id":"NDQW2rot7d0n"},"source":["### Arguments"],"id":"NDQW2rot7d0n"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d5b0649"},"outputs":[],"source":["# Define arguments with argparse.\n","import argparse\n","from distutils.util import strtobool\n","parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n","\n","# Experiment.\n","parser.add_argument('--dev-run', default=False, type=strtobool, help='Executes a fast dev run instead of fully training.')\n","parser.add_argument('--fresh-run', default=False, type=strtobool, help='Ignores all cashed data on disk, reruns generation and overwrites everything.')\n","parser.add_argument('--seed', default=0, type=int, help='The random seed of the program.')\n","parser.add_argument('--src-lang', default='de', type=str, help='The source language.')\n","parser.add_argument('--tgt-lang', default='nl', type=str, help='The target language.')\n","parser.add_argument('--eval-before-train', default=False, type=strtobool, help='Evaluate the model on the validation data before training.')\n","\n","# Metrics.\n","parser.add_argument('--track-bleu', default=True, type=strtobool, help='Whether to track the SacreBLEU score metric.')\n","parser.add_argument('--track-ter', default=False, type=strtobool, help='Whether to track the translation edit rate metric.')\n","parser.add_argument('--track-tp', default=False, type=strtobool, help='Whether to track the translation perplexity metric.')\n","parser.add_argument('--track-chrf', default=False, type=strtobool, help='Whether to track the CHRF score metric.')\n","\n","# Data.\n","parser.add_argument('--shuffle-before-split', default=False, type=strtobool, help='Whether to shuffle the data before creating the train, validation and test sets.')\n","parser.add_argument('--num-val-examples', default=3000, type=int, help='The number of validation examples.') \n","parser.add_argument('--num-test-examples', default=3000, type=int, help='The number of test examples.')\n","\n","# Tokenization.\n","parser.add_argument('--src-vocab-size', default=16000, type=int, help='The vocabulary size of the source language tokenizer.')\n","parser.add_argument('--src-char-coverage', default=1.0, type=float, help='The character coverage (percentage) of the source language tokenizer.')\n","parser.add_argument('--tgt-vocab-size', default=16000, type=int, help='The vocabulary size of the target language tokenizer.')\n","parser.add_argument('--tgt-char-coverage', default=1.0, type=float, help='The character coverage (percentage) of the target language tokenizer.')\n","\n","# Architecture.\n","parser.add_argument('--num-layers', default=6, type=int, help='The number of encoder and decoder layers.')\n","parser.add_argument('--d-model', default=512, type=int, help='The embedding size.')\n","parser.add_argument('--dropout-rate', default=0.1, type=float, help='The dropout rate.')\n","parser.add_argument('--num-heads', default=8, type=int, help='The number of attention heads.')\n","parser.add_argument('--d-ff', default=2048, type=int, help='The feed forward dimension.')\n","parser.add_argument('--max-len', default=128, type=int, help='The maximum sequence length.')\n","\n","# Optimizer.\n","parser.add_argument('--learning-rate', default=1e-4, type=float, help='The learning rate.')\n","parser.add_argument('--weight-decay', default=0, type=float, help='The weight decay.')\n","parser.add_argument('--beta-1', default=0.9, type=float, help='Beta_1 parameter of Adam.')\n","parser.add_argument('--beta-2', default=0.98, type=float, help='Beta_2 parameter of Adam.')\n","\n","# Scheduler.\n","parser.add_argument('--enable-scheduling', default=False, type=strtobool, help='Whether to enable scheduling.')\n","parser.add_argument('--warm-up-steps', default=4000, type=int, help='The number of warm up steps.')\n","\n","# Training.\n","parser.add_argument('--batch-size', default=80, type=int, help='The batch size.')\n","parser.add_argument('--label-smoothing', default=0, type=float, help='The amount of smoothing when calculating the loss.')\n","parser.add_argument('--max-epochs', default=10, type=int, help='The maximum number of training epochs.')\n","parser.add_argument('--max-examples', default=-1, type=int, help='The maximum number of training examples.')\n","parser.add_argument('--shuffle-train-data', default=True, type=strtobool, help='Whether to shuffle the training data during training.')\n","parser.add_argument('--gpus', default=1, type=int, help='The number of GPUs.')\n","parser.add_argument('--num-workers', default=4, type=int, help='The number of pytorch workers.')\n","parser.add_argument('--ckpt-path', default=None, type=str, help='The model checkpoint form which to resume training.')\n","\n","# Early Stopping + Model Checkpoint.\n","parser.add_argument('--enable-early-stopping', default=False, type=strtobool, help='Whether to enable early stopping.')\n","parser.add_argument('--enable-checkpointing', default=False, type=strtobool, help='Whether to enable checkpointing. The best and the last version of the model are saved.')\n","parser.add_argument('--monitor', default='val_loss', type=str, help='The metric to monitor.')\n","parser.add_argument('--min-delta', default=0, type=float, help='The minimum change the metric must achieve.')\n","parser.add_argument('--patience', default=3, type=int, help='Number of epochs that the monitored metric has time to improve.')\n","parser.add_argument('--mode', default='min', type=str, choices=['min', 'max'], help='How the monitored metric should improve.')\n","\n","# Parse args.\n","if is_notebook():\n","    sys.argv = ['-f']  # Used to make argparse work in jupyter notebooks (all args must be optional).\n","    args, _ = parser.parse_known_args()  # -f can lead to unknown argument.\n","else:\n","    args = parser.parse_args()\n","\n","# Print args.\n","print('Arguments:')\n","print(args)"],"id":"6d5b0649"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VWCabcjvgiT"},"outputs":[],"source":["# Auto-infer args.\n","auto_infer_args(args)"],"id":"2VWCabcjvgiT"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pEUXxmyTMmw"},"outputs":[],"source":["# Adjust arguments for test purposes.\n","if is_notebook() and True:  # Quickly turn on and off with 'and True/False'.\n","    #args.dev_run = True\n","    #args.fresh_run = True\n","\n","    args.max_epochs = 5\n","    args.batch_size = 1\n","    args.max_examples = 2\n","    args.num_val_examples = 1\n","    args.num_test_examples = 1\n","\n","    print('Adjusted args in notebook')"],"id":"5pEUXxmyTMmw"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jeeda_XMY5lZ"},"outputs":[],"source":["# Sanity check args.\n","sanity_check_args(args)"],"id":"Jeeda_XMY5lZ"},{"cell_type":"code","source":[],"metadata":{"id":"437o_EHJYsmf"},"id":"437o_EHJYsmf","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"602b6bab","metadata":{"id":"602b6bab"},"outputs":[],"source":["# Experiment paramereters.\n","hparams = dotdict({\n","    'src_lang': 'de',\n","    'pvt_lang': 'nl',\n","    'tgt_lang': 'en',\n","    'src_pvt_model_path': 'models/baseline-de-nl.pt',\n","    'pvt_tgt_model_path': 'models/baseline-nl-en.pt',\n","    'batch_size': 80,\n","    'max_epochs': 10,\n","    'max_examples': 10_000,\n","    'gpus': 1,\n","    'num_workers': 4,\n","    'ckpt_path': None,\n","})\n","\n","print('Experiment paramereters:')\n","print(hparams)"]},{"cell_type":"markdown","metadata":{"id":"OpSSObjs69g6"},"source":["### Seed"],"id":"OpSSObjs69g6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeC5Td1c69A7"},"outputs":[],"source":["# Set seed.\n","from pytorch_lightning import seed_everything\n","seed_everything(args.seed, workers=True)"],"id":"oeC5Td1c69A7"},{"cell_type":"markdown","metadata":{"id":"jcklieExTMm2"},"source":["### Paths"],"id":"jcklieExTMm2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"428bec54"},"outputs":[],"source":["# Create directories and create file names.\n","pm = ExperimentPathManager(f'direct-pivoting-{args.src_lang}-{args.tgt_lang}-{args.tgt_lang}', 'direct-pivoting')\n","pm.init()"],"id":"428bec54"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WHCPZbsxJKFP"},"outputs":[],"source":["# Save arguments.\n","save_dict(pm.args_file, args.__dict__)"],"id":"WHCPZbsxJKFP"},{"cell_type":"code","source":[],"metadata":{"id":"q1VVAjVaYkyS"},"id":"q1VVAjVaYkyS","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K6a1qtumYkvq"},"id":"K6a1qtumYkvq","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-FM4S6nLYkuA"},"id":"-FM4S6nLYkuA","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"77661284","metadata":{"id":"77661284"},"outputs":[],"source":["# Constant directories.\n","data_dir = os.path.join('./', 'data')\n","tokenizers_dir = os.path.join('./', 'tokenizers')\n","runs_dir = os.path.join('./', 'runs')\n","\n","# Experiment directories.\n","run_dir = os.path.join(runs_dir, f'direct-pivoting-{hparams.src_lang}-{hparams.pvt_lang}-{hparams.tgt_lang}-{get_time_as_string()}')\n","model_checkpoints_dir = os.path.join(run_dir, 'checkpoints')\n","results_dir = os.path.join(run_dir, 'results')\n","pre_training_eval_results_dir = os.path.join(run_dir, 'pre-training-eval-results')\n","\n","dirs = [data_dir, tokenizers_dir, runs_dir, run_dir, model_checkpoints_dir, results_dir, pre_training_eval_results_dir]\n","for dir in dirs:\n","    create_dir(dir)\n","\n","print('Created directories.')"]},{"cell_type":"code","execution_count":null,"id":"53c5a6e3","metadata":{"id":"53c5a6e3"},"outputs":[],"source":["# Load Metrics.\n","score_metric = load_metric('sacrebleu')\n","\n","print('Loaded metrics.')"]},{"cell_type":"code","execution_count":null,"id":"5484f36c","metadata":{"id":"5484f36c"},"outputs":[],"source":["# Download data.\n","download_data(hparams.src_lang, hparams.tgt_lang)"]},{"cell_type":"code","execution_count":null,"id":"b5d5b5cf","metadata":{"id":"b5d5b5cf"},"outputs":[],"source":["# Load tokenizers.\n","src_tokenizer = load_tokenizer(hparams.src_lang, hparams.tgt_lang)\n","pvt_tokenizer = load_tokenizer(hparams.pvt_lang, hparams.tgt_lang)\n","tgt_tokenizer = load_tokenizer(hparams.tgt_lang, hparams.src_lang)\n","\n","print('Loaded tokenizers.')"]},{"cell_type":"code","execution_count":null,"id":"7e3318ad","metadata":{"id":"7e3318ad"},"outputs":[],"source":["# Load data.\n","train_dataset, val_dataset, test_dataset = load_data(hparams.src_lang,\n","                                                     hparams.tgt_lang,\n","                                                     src_tokenizer,\n","                                                     tgt_tokenizer,\n","                                                     hparams.max_examples)\n","\n","print(f'Preprocessed data ({hparams.src_lang}-{hparams.tgt_lang})')\n","print(f'\\tTraining data:   {len(train_dataset)}')\n","print(f'\\tValidation data: {len(val_dataset)}')\n","print(f'\\tTest data:       {len(test_dataset)}')"]},{"cell_type":"code","execution_count":null,"id":"735e8245","metadata":{"id":"735e8245"},"outputs":[],"source":["# Create data loaders.\n","train_dataloader = DataLoader(train_dataset, batch_size=hparams.batch_size, num_workers=hparams.num_workers)\n","val_dataloader = DataLoader(val_dataset, batch_size=hparams.batch_size, num_workers=hparams.num_workers)\n","test_dataloader = DataLoader(test_dataset, batch_size=hparams.batch_size, num_workers=hparams.num_workers)\n","\n","print('Created data loaders.')"]},{"cell_type":"code","execution_count":null,"id":"9fb021c1","metadata":{"id":"9fb021c1"},"outputs":[],"source":["# Create models.\n","src_pvt_model = Transformer(src_tokenizer,\n","                            pvt_tokenizer,\n","                            score_metric=score_metric)\n","\n","pvt_tgt_model = Transformer(pvt_tokenizer,\n","                            tgt_tokenizer,\n","                            score_metric=score_metric)\n","\n","print('Created models.')"]},{"cell_type":"code","execution_count":null,"id":"6192cc78","metadata":{"scrolled":true,"id":"6192cc78"},"outputs":[],"source":["# Load models.\n","src_pvt_model.load_state_dict(torch.load(hparams.src_pvt_model_path))\n","pvt_tgt_model.load_state_dict(torch.load(hparams.pvt_tgt_model_path))\n","\n","src_pvt_model.to(device)\n","pvt_tgt_model.to(device)\n","\n","print('Loaded models.')"]},{"cell_type":"code","execution_count":null,"id":"1f12c039","metadata":{"id":"1f12c039"},"outputs":[],"source":["# Create direct pivoting model.\n","model = pvt_tgt_model\n","model.src_tokenizer = src_tokenizer\n","model.src_vocab_size = src_pvt_model.src_vocab_size\n","model.src_embedding = src_pvt_model.src_embedding\n","model.encoder = src_pvt_model.encoder"]},{"cell_type":"code","execution_count":null,"id":"1e5f5875","metadata":{"id":"1e5f5875"},"outputs":[],"source":["# Add aditional regularization to combat over-fitting on limited data.\n","model.set_dropout_rate(0.3)\n","model.weight_decay = 0.0"]},{"cell_type":"code","execution_count":null,"id":"aae1f49b","metadata":{"id":"aae1f49b"},"outputs":[],"source":["# Create trainer.\n","metric_logger = MetricLogger()\n","checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","          dirpath=model_checkpoints_dir,\n","          verbose=True,\n","          save_last=True,\n","      )\n","\n","trainer = Trainer(deterministic=True,\n","                  fast_dev_run=False,\n","                  max_epochs=hparams.max_epochs,\n","                  logger=metric_logger,\n","                  log_every_n_steps=1,\n","                  enable_checkpointing=True,\n","                  default_root_dir=model_checkpoints_dir,\n","                  callbacks=[checkpoint_callback],\n","                  gpus=hparams.gpus if str(device) == 'cuda' else 0)\n","\n","print('Created trainer.')"]},{"cell_type":"code","execution_count":null,"id":"cdfcf7d4","metadata":{"id":"cdfcf7d4"},"outputs":[],"source":["# Save untrained model.\n","model_path = os.path.join(pre_training_eval_results_dir, 'model.pt')\n","torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","execution_count":null,"id":"41535c01","metadata":{"id":"41535c01"},"outputs":[],"source":["# Evaluate performance.\n","test_metrics = trainer.test(model, dataloaders=test_dataloader)\n","print(test_metrics)\n","metric_logger.manual_save(pre_training_eval_results_dir)\n","metric_logger.reset()"]},{"cell_type":"code","execution_count":null,"id":"4caf9790","metadata":{"id":"4caf9790"},"outputs":[],"source":["# Training.\n","trainer.fit(model,\n","            train_dataloaders=train_dataloader,\n","            val_dataloaders=val_dataloader)"]},{"cell_type":"code","execution_count":null,"id":"7c022dcc","metadata":{"id":"7c022dcc"},"outputs":[],"source":["# Save model.\n","model_path = os.path.join(run_dir, 'model.pt')\n","torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","execution_count":null,"id":"4faadbeb","metadata":{"id":"4faadbeb"},"outputs":[],"source":["# Testing.\n","test_metrics = trainer.test(model, dataloaders=test_dataloader)\n","print(test_metrics)"]},{"cell_type":"code","execution_count":null,"id":"1c235a1d","metadata":{"id":"1c235a1d"},"outputs":[],"source":["# Plot loss metrics.\n","save_path = os.path.join(results_dir, 'loss.svg')\n","plot_metric(metric_logger.metrics, 'loss', 'Loss', save_path=save_path)"]},{"cell_type":"code","execution_count":null,"id":"807a0c7d","metadata":{"id":"807a0c7d"},"outputs":[],"source":["# Plot score metric.\n","save_path = os.path.join(results_dir, 'score.svg')\n","plot_metric(metric_logger.metrics, 'score', 'Score', save_path=save_path)"]},{"cell_type":"code","execution_count":null,"id":"59167622","metadata":{"id":"59167622"},"outputs":[],"source":["# Save hyper parameters.\n","save_dict(run_dir, hparams, 'hparams')"]},{"cell_type":"code","execution_count":null,"id":"8b5e8e7e","metadata":{"id":"8b5e8e7e"},"outputs":[],"source":["# Save recorded metrics.\n","metric_logger.manual_save(results_dir)"]},{"cell_type":"code","execution_count":null,"id":"99a80348","metadata":{"id":"99a80348"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"e16c6ae93e97f8b72f7c60789e33aa05f059bdee2efc0781f4556fc1fbea3a2d"}},"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}