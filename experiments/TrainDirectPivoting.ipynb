{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e219183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src module directory to system path for subsecuent imports.\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa380261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import is_notebook\n",
    "\n",
    "# Settings (only in Jupyter Notebooks).\n",
    "if is_notebook():\n",
    "    # Module reloading.\n",
    "    %load_ext autoreload\n",
    "    # aimport?\n",
    "    %autoreload 2\n",
    "    # Plot settings.\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843ca766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_metric\n",
    "\n",
    "from constants import *\n",
    "from util import *\n",
    "from transformer import Transformer\n",
    "from tokenizer import load_tokenizer\n",
    "from data import download_data, load_data\n",
    "from plotting import plot_metric\n",
    "from metric_logging import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb963cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed.\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(0, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "602b6bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment paramereters:\n",
      "{'src_lang': 'de', 'pvt_lang': 'nl', 'tgt_lang': 'en', 'src_pvt_model_path': 'models/baseline-de-nl.pt', 'pvt_tgt_model_path': 'models/baseline-nl-en.pt', 'batch_size': 80, 'max_epochs': 10, 'max_examples': -1, 'gpus': 1, 'num_workers': 4, 'ckpt_path': None}\n"
     ]
    }
   ],
   "source": [
    "# Experiment paramereters.\n",
    "hparams = dotdict({\n",
    "    'src_lang': 'de',\n",
    "    'pvt_lang': 'nl',\n",
    "    'tgt_lang': 'en',\n",
    "    'src_pvt_model_path': 'models/baseline-de-nl.pt',\n",
    "    'pvt_tgt_model_path': 'models/baseline-nl-en.pt',\n",
    "    'batch_size': 80,\n",
    "    'max_epochs': 10,\n",
    "    'max_examples': 10_000,\n",
    "    'gpus': 1,\n",
    "    'num_workers': 4,\n",
    "    'ckpt_path': None,\n",
    "})\n",
    "\n",
    "print('Experiment paramereters:')\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77661284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir \"./data\" already exists.\n",
      "Dir \"./runs\" already exists.\n",
      "Dir \"./runs\\direct-pivoting-de-nl-en-2022.09.15-16.53.59\" does not exist, creating it.\n",
      "Dir \"./runs\\direct-pivoting-de-nl-en-2022.09.15-16.53.59\\checkpoints\" does not exist, creating it.\n",
      "Dir \"./runs\\direct-pivoting-de-nl-en-2022.09.15-16.53.59\\results\" does not exist, creating it.\n",
      "Dir \"./runs\\direct-pivoting-de-nl-en-2022.09.15-16.53.59\\pre-training-eval-results\" does not exist, creating it.\n",
      "Created directories.\n"
     ]
    }
   ],
   "source": [
    "# Constant directories.\n",
    "data_dir = os.path.join('./', 'data')\n",
    "tokenizers_dir = os.path.join('./', 'tokenizers')\n",
    "runs_dir = os.path.join('./', 'runs')\n",
    "\n",
    "# Experiment directories.\n",
    "run_dir = os.path.join(runs_dir, f'direct-pivoting-{hparams.src_lang}-{hparams.pvt_lang}-{hparams.tgt_lang}-{get_time_as_string()}')\n",
    "model_checkpoints_dir = os.path.join(run_dir, 'checkpoints')\n",
    "results_dir = os.path.join(run_dir, 'results')\n",
    "pre_training_eval_results_dir = os.path.join(run_dir, 'pre-training-eval-results')\n",
    "\n",
    "dirs = [data_dir, tokenizers_dir, runs_dir, run_dir, model_checkpoints_dir, results_dir, pre_training_eval_results_dir]\n",
    "for dir in dirs:\n",
    "    create_dir(dir)\n",
    "\n",
    "print('Created directories.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c5a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metrics.\n"
     ]
    }
   ],
   "source": [
    "# Load Metrics.\n",
    "score_metric = load_metric('sacrebleu')\n",
    "\n",
    "print('Loaded metrics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5484f36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File \"data\\de-en.zip\" already exists. Skipping download.\n",
      "Directory data\\de-en already exists. Skipping unzipping.\n"
     ]
    }
   ],
   "source": [
    "# Download data.\n",
    "download_data(hparams.src_lang, hparams.tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d5b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer exists. Skipping training.\n",
      "Tokenizer exists. Skipping training.\n",
      "Tokenizer exists. Skipping training.\n",
      "Loaded tokenizers.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizers.\n",
    "src_tokenizer = load_tokenizer(hparams.src_lang, hparams.tgt_lang)\n",
    "pvt_tokenizer = load_tokenizer(hparams.pvt_lang, hparams.tgt_lang)\n",
    "tgt_tokenizer = load_tokenizer(hparams.tgt_lang, hparams.src_lang)\n",
    "\n",
    "print('Loaded tokenizers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3318ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data exists, loading from disk...\n",
      "Splitting de-en data...\n",
      "Data (de-en) split.\n",
      "Preprocessed data (de-en)\n",
      "\tTraining data:   1416094\n",
      "\tValidation data: 78671\n",
      "\tTest data:       78671\n"
     ]
    }
   ],
   "source": [
    "# Load data.\n",
    "train_dataset, val_dataset, test_dataset = load_data(hparams.src_lang,\n",
    "                                                     hparams.tgt_lang,\n",
    "                                                     src_tokenizer,\n",
    "                                                     tgt_tokenizer,\n",
    "                                                     hparams.max_examples)\n",
    "\n",
    "print(f'Preprocessed data ({hparams.src_lang}-{hparams.tgt_lang})')\n",
    "print(f'\\tTraining data:   {len(train_dataset)}')\n",
    "print(f'\\tValidation data: {len(val_dataset)}')\n",
    "print(f'\\tTest data:       {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735e8245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data loaders.\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=hparams.batch_size, num_workers=hparams.num_workers)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=hparams.batch_size, num_workers=hparams.num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=hparams.batch_size, num_workers=hparams.num_workers)\n",
    "\n",
    "print('Created data loaders.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb021c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created models.\n"
     ]
    }
   ],
   "source": [
    "# Create models.\n",
    "src_pvt_model = Transformer(src_tokenizer,\n",
    "                            pvt_tokenizer,\n",
    "                            score_metric=score_metric)\n",
    "\n",
    "pvt_tgt_model = Transformer(pvt_tokenizer,\n",
    "                            tgt_tokenizer,\n",
    "                            score_metric=score_metric)\n",
    "\n",
    "print('Created models.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6192cc78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models.\n"
     ]
    }
   ],
   "source": [
    "# Load models.\n",
    "src_pvt_model.load_state_dict(torch.load(hparams.src_pvt_model_path))\n",
    "pvt_tgt_model.load_state_dict(torch.load(hparams.pvt_tgt_model_path))\n",
    "\n",
    "src_pvt_model.to(device)\n",
    "pvt_tgt_model.to(device)\n",
    "\n",
    "print('Loaded models.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f12c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create direct pivoting model.\n",
    "model = pvt_tgt_model\n",
    "model.src_tokenizer = src_tokenizer\n",
    "model.src_vocab_size = src_pvt_model.src_vocab_size\n",
    "model.src_embedding = src_pvt_model.src_embedding\n",
    "model.encoder = src_pvt_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e5f5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add aditional regularization to combat over-fitting on limited data.\n",
    "model.set_dropout_rate(0.3)\n",
    "model.weight_decay = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aae1f49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created trainer.\n"
     ]
    }
   ],
   "source": [
    "# Create trainer.\n",
    "metric_logger = MetricLogger()\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "          dirpath=model_checkpoints_dir,\n",
    "          verbose=True,\n",
    "          save_last=True,\n",
    "      )\n",
    "\n",
    "trainer = Trainer(deterministic=True,\n",
    "                  fast_dev_run=False,\n",
    "                  max_epochs=hparams.max_epochs,\n",
    "                  logger=metric_logger,\n",
    "                  log_every_n_steps=1,\n",
    "                  enable_checkpointing=True,\n",
    "                  default_root_dir=model_checkpoints_dir,\n",
    "                  callbacks=[checkpoint_callback],\n",
    "                  gpus=hparams.gpus if str(device) == 'cuda' else 0)\n",
    "\n",
    "print('Created trainer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdfcf7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save untrained model.\n",
    "model_path = os.path.join(pre_training_eval_results_dir, 'model.pt')\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41535c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c421c279f547b18c0371eaa0816b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_loss_epoch        1.2056682109832764\n",
      "    test_score_epoch        0.7950282692909241\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[{'test_loss_epoch': 1.2056682109832764, 'test_score_epoch': 0.7950282692909241}]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance.\n",
    "test_metrics = trainer.test(model, dataloaders=test_dataloader)\n",
    "print(test_metrics)\n",
    "metric_logger.manual_save(pre_training_eval_results_dir)\n",
    "metric_logger.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4caf9790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name               | Type              | Params\n",
      "---------------------------------------------------------\n",
      "0 | src_embedding      | Embedding         | 8.2 M \n",
      "1 | tgt_embedding      | Embedding         | 8.2 M \n",
      "2 | positional_encoder | PositionalEncoder | 0     \n",
      "3 | encoder            | Encoder           | 18.9 M\n",
      "4 | decoder            | Decoder           | 25.2 M\n",
      "5 | output_linear      | Linear            | 8.2 M \n",
      "6 | softmax            | LogSoftmax        | 0     \n",
      "---------------------------------------------------------\n",
      "68.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.7 M    Total params\n",
      "274.930   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3db05fc7f6f47b5bf2cb5c5ee413b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training.\n",
    "trainer.fit(model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c022dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model.\n",
    "model_path = os.path.join(run_dir, 'model.pt')\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4faadbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea6ff47eca845a0a16dd641e7e4c91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_loss_epoch        1.1716341972351074\n",
      "    test_score_epoch        0.8549150228500366\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[{'test_loss_epoch': 1.1716341972351074, 'test_score_epoch': 0.8549150228500366}]\n"
     ]
    }
   ],
   "source": [
    "# Testing.\n",
    "test_metrics = trainer.test(model, dataloaders=test_dataloader)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c235a1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot loss metrics.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss.svg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplot_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric_logger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLoss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\transformer-based-nmt-recipe\\experiments\\../src\\plotting.py:15\u001b[0m, in \u001b[0;36mplot_metric\u001b[1;34m(metrics, metric, title, save_path, test_only)\u001b[0m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epoch_steps, metrics[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m], linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (epochs)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epoch_steps, metrics[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m], linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (epochs)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([epochs], [\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmetric\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m], linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, markersize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcyan\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(title)\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss metrics.\n",
    "save_path = os.path.join(results_dir, 'loss.svg')\n",
    "plot_metric(metric_logger.metrics, 'loss', 'Loss', save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot score metric.\n",
    "save_path = os.path.join(results_dir, 'score.svg')\n",
    "plot_metric(metric_logger.metrics, 'score', 'Score', save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59167622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hyper parameters.\n",
    "save_dict(run_dir, hparams, 'hparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save recorded metrics.\n",
    "metric_logger.manual_save(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a80348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e16c6ae93e97f8b72f7c60789e33aa05f059bdee2efc0781f4556fc1fbea3a2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
