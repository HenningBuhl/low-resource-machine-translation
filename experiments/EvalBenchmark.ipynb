{"cells":[{"cell_type":"code","execution_count":null,"id":"58da323c","metadata":{"id":"58da323c"},"outputs":[],"source":["# Add src module directory to system path for subsecuent imports.\n","import os\n","import sys\n","sys.path.insert(0, '../src')"]},{"cell_type":"code","execution_count":null,"id":"844423ca","metadata":{"id":"844423ca"},"outputs":[],"source":["from util import is_notebook\n","\n","# Settings (only in Jupyter Notebooks).\n","if is_notebook():\n","    # Module reloading.\n","    %load_ext autoreload\n","    # aimport?\n","    %autoreload 2\n","    # Plot settings.\n","    %matplotlib inline"]},{"cell_type":"code","execution_count":null,"id":"060a4467","metadata":{"id":"060a4467"},"outputs":[],"source":["# Imports.\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer\n","from torch.utils.data import DataLoader\n","from datasets import load_metric\n","\n","from constants import *\n","from util import *\n","from transformer import Transformer, cascaded_inference\n","from tokenizer import load_tokenizer\n","from data import download_data, load_data\n","from plotting import plot_metric\n","from metric_logging import MetricLogger\n","from benchmark import *"]},{"cell_type":"code","execution_count":null,"id":"fa8e7b47","metadata":{"id":"fa8e7b47"},"outputs":[],"source":["# Set seed.\n","from pytorch_lightning import seed_everything\n","seed_everything(0, workers=True)"]},{"cell_type":"code","execution_count":null,"id":"0283783c","metadata":{"id":"0283783c"},"outputs":[],"source":["# Experiment variables.\n","\n","# List of models to be evaluated.\n","model_configs = [\n","    # Baseline and cascaded.\n","    ModelConfig('single', ('de', 'en'), './models/baseline-de-en.pt'),\n","    ModelConfig('single', ('de', 'nl'), './models/baseline-de-nl.pt'),\n","    ModelConfig('single', ('nl', 'en'), './models/baseline-nl-en.pt'),\n","    ModelConfig('cascaded', ('de', 'nl', 'en'), ['./models/baseline-de-nl.pt', './models/baseline-nl-en.pt'], 'cascaded-de-nl-en'),\n","    # Baseline (limited de-en).\n","    ModelConfig('single', ('de', 'en'), './models/baseline-de-en-10000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/baseline-de-en-20000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/baseline-de-en-50000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/baseline-de-en-100000-examples.pt'),\n","    # Direct pivoting.\n","    ModelConfig('single', ('de', 'en'), './models/direct-pivoting-de-nl-en.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/direct-pivoting-de-nl-en-10000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/direct-pivoting-de-nl-en-20000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/direct-pivoting-de-nl-en-50000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/direct-pivoting-de-nl-en-100000-examples.pt'),\n","    # Step-wise pivoting.\n","    ModelConfig('single', ('de', 'en'), './models/step-wise-pivoting-de-nl-en.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/step-wise-pivoting-de-nl-en-10000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/step-wise-pivoting-de-nl-en-20000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/step-wise-pivoting-de-nl-en-50000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/step-wise-pivoting-de-nl-en-100000-examples.pt'),\n","    ModelConfig('single', ('nl', 'en'), './models/step-wise-pivoting-de-nl-en-step-2.pt'),\n","    # Reverse step-wise pivoting.\n","    ModelConfig('single', ('de', 'en'), './models/reverse-step-wise-pivoting-de-nl-en.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/reverse-step-wise-pivoting-de-nl-en-10000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/reverse-step-wise-pivoting-de-nl-en-20000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/reverse-step-wise-pivoting-de-nl-en-50000-examples.pt'),\n","    ModelConfig('single', ('de', 'en'), './models/reverse-step-wise-pivoting-de-nl-en-100000-examples.pt'),\n","    ModelConfig('single', ('de', 'nl'), './models/reverse-step-wise-pivoting-de-nl-en-step-2.pt'),\n","]\n","\n","# List of benchmarks to be applied to models.\n","benchmark_configs = [\n","    BenchmarkConfig('flores', flores_collate_fn, flores_pp_fn),\n","    BenchmarkConfig('tatoeba', tatoeba_collate_fn, tatoeba_pp_fn),\n","]"]},{"cell_type":"code","execution_count":null,"id":"428bec54","metadata":{"id":"428bec54"},"outputs":[],"source":["# Constant directories.\n","data_dir = os.path.join('./', 'data')\n","tokenizers_dir = os.path.join('./', 'tokenizers')\n","runs_dir = os.path.join('./', 'runs')\n","\n","# Experiment directories.\n","run_dir = os.path.join(runs_dir, f'benchmark-{get_time_as_string()}')\n","\n","dirs = [data_dir, tokenizers_dir, runs_dir, run_dir]\n","for dir in dirs:\n","    create_dir(dir)\n","\n","print('Created directories.')"]},{"cell_type":"code","execution_count":null,"id":"d4338e51","metadata":{"scrolled":true,"id":"d4338e51"},"outputs":[],"source":["# Load Metrics.\n","score_metric = load_metric('sacrebleu')\n","\n","print('Loaded metrics.')"]},{"cell_type":"code","execution_count":null,"id":"d2e00bc4","metadata":{"id":"d2e00bc4"},"outputs":[],"source":["# Experiment paramereters.\n","hparams = dotdict({\n","    'beam_size': 8,\n","    'top_k': 15,\n","    'top_p': 0.6,\n","    'num_workers': 4,\n","})\n","\n","print('Experiment paramereters:')\n","print(hparams)"]},{"cell_type":"code","execution_count":null,"id":"6d016f19","metadata":{"id":"6d016f19"},"outputs":[],"source":["# Perform benchmark...\n","for bc in benchmark_configs:\n","    print(f'Performing \"{bc.name}\" benchmark on {len(model_configs)} models.')\n","    \n","    # Create directories.\n","    benchmark_dir = os.path.join(run_dir, bc.name)\n","    dirs = [benchmark_dir]\n","    for dir in dirs:\n","        create_dir(dir)\n","    \n","    # Download and unpack data.\n","    bc.collate_fn(data_dir)\n","    \n","    # ... on every model.\n","    for mc in model_configs:\n","        print(f'\\tBenchmarking {mc.name} ({mc.langs}) on {bc.name}.')\n","        \n","        # Create directories.\n","        results_dir = os.path.join(benchmark_dir, mc.name)\n","        dirs = [results_dir]\n","        for dir in dirs:\n","            create_dir(dir)\n","        \n","        method_kwargs = {\n","            'greedy': {},\n","            'beam': {'beam_size': hparams.beam_size},\n","            'top_k': {'top_k': hparams.top_k},\n","            'top_p': {'top_p': hparams.top_p},\n","        }\n","        test_results = {k: 0 for k in method_kwargs.keys()}\n","        for method, kwargs in method_kwargs.items():\n","            print(f'\\t\\tBenchmarking {mc.name} ({mc.langs}) on {bc.name} with inference method {method}.')\n","\n","            # Perform evaluation base on mc.type.\n","            if mc.type == 'single':\n","                src_lang, tgt_lang = mc.langs\n","\n","                # Load tokenizers.\n","                src_tokenizer = load_tokenizer(src_lang, tgt_lang)\n","                tgt_tokenizer = load_tokenizer(tgt_lang, src_lang)\n","                print('\\t\\tLoaded tokenizers.')\n","\n","                # Load data.\n","                dataset = bc.pp_fn(data_dir, src_lang, tgt_lang, src_tokenizer, tgt_tokenizer)\n","                print('\\t\\tLoaded data.')\n","\n","                # Create dataloader.\n","                test_dataloader = DataLoader(dataset, batch_size=1, num_workers=hparams.num_workers)\n","                print('\\t\\tCreated data loader.')\n","\n","                # Create model.\n","                model = Transformer(src_tokenizer,\n","                        tgt_tokenizer,\n","                        score_metric=score_metric)\n","                print('\\t\\tCreated model.')\n","\n","                # Load model.\n","                model.load_state_dict(torch.load(mc.paths))\n","                model.to(device)\n","                print('\\t\\tLoaded model.')\n","\n","                # Testing.\n","                for batch_idx, batch in enumerate(test_dataloader):\n","                    src_input, tgt_input, tgt_output = batch \n","                    \n","                    # Convert preprocessed input back to text.\n","                    src_text = src_tokenizer.Decode(src_input.tolist())[0]\n","                    label_text = tgt_tokenizer.Decode(tgt_input.tolist())[0]\n","\n","                    # Pass through model.\n","                    tgt_text = model.translate(src_text, method='sampling' if 'top' in method else method, kwargs=kwargs)\n","\n","                    # Calculate metrics.\n","                    score = score_metric.compute(predictions=[tgt_text], references=[[label_text]])['score']\n","                    \n","                    # Accumulate metrics.\n","                    test_results[method] += score\n","                    print(f'\\t\\t{score}')\n","                test_results[method] = [test_results[method] / len(dataset)]\n","\n","            elif mc.type == 'cascaded':\n","                src_lang, pvt_lang, tgt_lang = mc.langs\n","\n","                # Load tokenizers.\n","                src_tokenizer = load_tokenizer(src_lang, tgt_lang)\n","                pvt_tokenizer = load_tokenizer(pvt_lang, tgt_lang)\n","                tgt_tokenizer = load_tokenizer(tgt_lang, src_lang)\n","                print('\\t\\tLoaded tokenizers.')\n","\n","                # Load data.\n","                dataset = bc.pp_fn(data_dir, src_lang, tgt_lang, src_tokenizer, tgt_tokenizer)\n","                print('\\t\\tLoaded data.')\n","\n","                # Create dataloader.\n","                test_dataloader = DataLoader(dataset, batch_size=1, num_workers=hparams.num_workers)\n","                print('\\t\\tCreated data loader.')\n","\n","                # Create model.\n","                src_pvt_model = Transformer(src_tokenizer,\n","                                            pvt_tokenizer,\n","                                            score_metric=score_metric)\n","                pvt_tgt_model = Transformer(pvt_tokenizer,\n","                                            tgt_tokenizer,\n","                                            score_metric=score_metric)\n","                print('\\t\\tCreated models.')\n","\n","                # Load model.\n","                src_pvt_model.load_state_dict(torch.load(mc.paths[0]))\n","                pvt_tgt_model.load_state_dict(torch.load(mc.paths[1]))\n","                src_pvt_model.to(device)\n","                pvt_tgt_model.to(device)\n","                print('\\t\\tLoaded models.')\n","\n","                # Testing.\n","                for batch_idx, batch in enumerate(test_dataloader):\n","                    # Cascaded inference.\n","                    score, src_text, pvt_text, tgt_text, label_text = cascaded_inference(batch,\n","                                                                                         src_tokenizer, tgt_tokenizer,\n","                                                                                         src_pvt_model, pvt_tgt_model,\n","                                                                                         score_metric,\n","                                                                                         method='sampling' if 'top' in method else method,\n","                                                                                         kwargs=kwargs)\n","                    # Accumulate metrics.\n","                    test_results[method] += score\n","                    print(f'\\t\\t{score}')\n","                test_results[method] = [test_results[method] / len(dataset)]\n","\n","            else:\n","                raise ValueError(f'Unknown model_config.type: {mc.type}')\n","\n","        # Save recorded metrics.\n","        save_dict(results_dir, test_results, 'metrics')"]},{"cell_type":"code","execution_count":null,"id":"594195d5","metadata":{"id":"594195d5"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"e16c6ae93e97f8b72f7c60789e33aa05f059bdee2efc0781f4556fc1fbea3a2d"}},"colab":{"private_outputs":true,"provenance":[]}},"nbformat":4,"nbformat_minor":5}